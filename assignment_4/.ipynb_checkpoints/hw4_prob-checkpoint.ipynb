{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed98045-ab30-47b3-ae5f-aa566e0d73fe",
   "metadata": {},
   "source": [
    "# HW4: Naive Bayes Classifier\n",
    "\n",
    "***참고: 이번 과제4는 Northwestern 대학 Ling334 수업의 자료를 기반으로 함***\n",
    "***https://faculty.wcas.northwestern.edu/robvoigt/courses/2021_spring/ling334/assignments/a3.html***\n",
    "\n",
    "이번 과제에서는 스팸 메일을 분류할 수 있는 bag of words 기반 Naïve Bayes classifier를 구현하고, 테스트 데이터에 대해 classifier의 성능을 평가할 수 있는 프로그램을 구현함.\n",
    "Bag of words 기반의 Naïve Bayes Classifier에서는 아래 그림과 같이 학습용 텍스트 데이터에서 모든 word에 대한 dictionary(bag)를 생성한 후, 학습용 텍스트에서 각 word가 등장한 횟수를 세고, 이렇게 구축된 통계를 기반으로 문서 전체의 종류를 구분함:\n",
    "\n",
    "<img src=\"slp_ch4-fig4-1.png\" alt=\"그림1: Bag-of-words 기반의 Naïve Bayes Classifier의 기본 개념\" width=\"640\"/>\n",
    "\n",
    "\n",
    "본 과제에서는 2010년도 아이티 대지진 이후 널리 도움을 요청하는 crowdsourcing 프로젝트(<a href=\"https://www.mission4636.org/\">mission 4636</a>)에서 수집된 데이터를 활용하며, 텍스트는 도움 요청과 관련되거나(`relevant`) 도움 요청과 무관한(`irrelevant`) 두 종류 중 하나로 분류됨.\n",
    "\n",
    "\n",
    "세부적으로 프로그래밍할 부분은 `naive_bayes.py` 파일 내 `NaiveBayesClassifier` class의 멤버 함수들 내부에 있으며, 학습용 텍스트 데이터로부터 word에 대한 통계(bag-of-words)를 구축하는 과정 및 이를 기반으로 문서를 분류하는 알고리즘은 아래 그림과 같이 정리됨:\n",
    "\n",
    "<img src=\"slp_ch4-fig4-2.png\" alt=\"그림1: Bag-of-words 기반의 Naïve Bayes Classifier의 알고리즘\" width=\"540\"/>\n",
    "\n",
    "위의 알고리즘에서 D는 전체 training data를 의미하는데, 본 과제의 학습용 텍스트 데이터에서는 각 클래스의 이름에 대응되는 `relevant` 및 `irrelevant`라는 이름의 파일들로 구성되며, 각 파일 내 하나하나의 line이 위 알고리즘에서 언급하는 각각의 document가 됨.\n",
    "\n",
    "***관련 참고문헌: <a href=\"https://web.stanford.edu/~jurafsky/slp3/4.pdf\">Ch.4, Speech and Language Processing (3rd ed. draft)\n",
    "by Dan Jurafsky and James H. Martin</a>***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb284b5-6251-4a65-ac21-02777ae4d3b5",
   "metadata": {},
   "source": [
    "### 구현문제1: naive Bayes의 training 코드 구현\n",
    "\n",
    "파일 `naive_bayes.py` 내부의 `class NaiveBayesClassifier`의 `train()` 함수를 구현하시오.\n",
    "\n",
    "위의 Figure 4.2에서 제시되는 TrainNaiveBayes 함수의 의사코드(pseudocode)를 참고하여 NaiveBayesClassifier class에서 관련되는 class attribute들 (self.vocabulary, self.logprior, 및 self.loglikelihood)의 값이 업데이트되도록 하는 코드를 구현하시오. 이때 self.vocabulary는 Python set() 형식, self.logprior는 string 형태의 key = class이름, 그리고 self.loglikelihood는 tuple 형식의 key = (word, class)인Python dictionary 형태로 생성하시오.\n",
    "\n",
    "(`__init__()`, `train()` 함수 내 설명 참고)\n",
    "\n",
    "다음 셀을 실행하여 해당 함수를 호출할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038803f-1fae-40ce-8db8-5d741047319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import naive_bayes\n",
    "clf = naive_bayes.NaiveBayesClassifier(train_dir = 'haiti/train')\n",
    "clf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0a64d-e6fc-4794-ad28-d46d0f1ced98",
   "metadata": {},
   "source": [
    "### 구현문제2: naive Bayes의 testing 코드 구현\n",
    "\n",
    "파일 `naive_bayes.py` 내부의 `score()`, `predict()`, `evaluate()` 함수를 구현하시오.\n",
    "\n",
    "위의 Figure 4.2에서 제시되는 TrainNaiveBayes 함수의 의사코드(pseudocode)를 참고하여 해당 함수에서 관련되는 class variable들 (self.vocabulary, self.logprior, 및 self.loglikelihood)의 값이 업데이트되도록 하는 코드를 구현하시오. 이때 self.loglikelihood는 shape가 (word의 개수, class의 개수)인numpy nd-array 형태로 생성하시오.\n",
    "\n",
    "(`score()`, `predict()`, `evaluate()` 함수 내 설명 참고)\n",
    "\n",
    "다음 셀을 실행하여 해당 함수를 호출하여 테스트 데이터에 대한 추정 결과를 도출할 수 있으며, 이때의 결과는 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1bfc50-6787-4e96-a68c-367f1374fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'relevant'\n",
    "print(f'Performance on class <{target.upper()}>, keeping stopwords')\n",
    "\n",
    "precision, recall, f1_score = clf.evaluate(test_dir = 'haiti/dev', target = target)\n",
    "print(f'\\tPrecision: {precision}\\t Recall: {recall}\\t F1: {f1_score}\\n')\n",
    "\n",
    "clf.print_top_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a562d-d718-4fcb-9aeb-002e4c254079",
   "metadata": {},
   "source": [
    "### 구현문제3: naive Bayes의 training 코드 구현 - stopwords를 제외하고 학습\n",
    "\n",
    "파일 `naive_bayes.py` 내부의 `class NaiveBayesClassifier`의 `train_stopwords()` 함수를 구현하시오.\n",
    "\n",
    "구현문제1과 유사하지만, `class NaiveBayesClassifier`의 `__init__()` 함수에서 사전에 읽어들인 self.stopwords에 해당하는 단어들을 제외하여 학습하는 코드를 구현하시오. \n",
    "\n",
    "(`train_stopwords()` 함수 내 설명 참고)\n",
    "\n",
    "다음 셀을 실행하면 구현된 `train_stopwords()` 함수를 통해 학습된 `NaiveBayesClassifier`로 새롭게 test 데이터에 대한 추정 결과를 도출할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f4bf4-fc18-413d-9059-789fecd828d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import naive_bayes\n",
    "target = 'relevant'\n",
    "\n",
    "clf = naive_bayes.NaiveBayesClassifier(train_dir = 'haiti/train')\n",
    "clf.train_stopwords()\n",
    "\n",
    "print(f'Performance on class <{target.upper()}>, removing stopwords')\n",
    "precision, recall, f1_score = clf.evaluate(test_dir = 'haiti/dev', target = target)\n",
    "print(f'\\tPrecision: {precision}\\t Recall: {recall}\\t F1: {f1_score}\\n')\n",
    "\n",
    "clf.print_top_features()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
