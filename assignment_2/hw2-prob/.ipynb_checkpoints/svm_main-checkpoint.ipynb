{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Multiclass Support Vector Machine 연습문제\n",
    "\n",
    "아래의 노트북 파일의 각 셀에 해당하는 문제의 답을, 외부 파일에 구현해야 하는 코딩까지 포함하여, 도출하시오.\n",
    "\n",
    "본 연습문제에서 여러분은 다음의 사항을 완수해야 함:\n",
    "    \n",
    "- Linear classification의 강의동영상에서 설명드린 Multiclass SVM **loss function**을 계산하는 Python 함수를 구현함. 이때 Numpy를 이용하여 해당 함수를 완전 벡터화된fully-vectorized 방식으로 구현함.\n",
    "- Multiclass SVM의 fully-vectorized loss function에 대응되는, **analytic gradient**를 계산하는 함수를 구현함. 역시 Numpy를 이용하여 해당 함수를 완전 벡터화된fully-vectorized 방식으로 구현함.\n",
    "- **numerical gradient**를 계산하는 함수를 함께 구현하여, 앞서 구현한 analytic gradient의 유효성 여부를 **check**함\n",
    "- Validation set을 이용하여 hyperparameter들, 즉 **learning rate** 및 **regularization strength**의 최적값을 도출함\n",
    "- **SGD**를 이용하여 구현한 loss function의 **최적화**함\n",
    "- 학습 결과로 도출된 weight parameter들을 **시각화**함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀1: 본 노트북의 환경 설정을 위한 코드\n",
    "\n",
    "필요한 패키지 임포트, 그래프plot 크기 설정, 영상 config 설정 등 수행하며, 별도의 코딩 없이 수행만 시키면 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "## 셀2-6: CIFAR-10 Data Loading and Preprocessing\n",
    "\n",
    "다음 셀들은 모두 데이터 불러오기 및 전처리 등을 수행하며, 역시 별도의 코딩 없이 수행만 시키면 됨.\n",
    "\n",
    "### 셀2: Data loading\n",
    "\n",
    "셀2: CIFAR-10 dataset를 파일로부터 읽어온 후, 데이터가 제대로 읽혔는지를 확인하기 위해 dataset이 저장된 변수의 차원을 프린트함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀3: Data visualization\n",
    "\n",
    "셀3: CIFAR-10 dataset의 각 클래스 이름을 변수에 저장하고, 각 클래스별로 랜덤하게 7개의 영상을 이미지로 화면에 표시함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀4: Dataset partition\n",
    "\n",
    "전체 학습 dataset을 i) 모델 학습에 사용할 training set, ii) hyperparameter tuning에 사용할 validation set, 그리고 iii) 코딩 과정에서 코드의 유효성을 확인하기 위한 용도인 소량의 development set으로 분할함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Split the data into train, val, and test sets. In addition we will\n",
    "# create a small development set as a subset of the training data;\n",
    "# we can use this for development so our code runs faster.\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "num_test = 1000\n",
    "num_dev = 500\n",
    "\n",
    "# Our validation set will be num_validation points from the original\n",
    "# training set.\n",
    "mask = range(num_training, num_training + num_validation)\n",
    "X_val = X_train[mask]\n",
    "y_val = y_train[mask]\n",
    "\n",
    "# Our training set will be the first num_train points from the original\n",
    "# training set.\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "# We will also make a development set, which is a small subset of\n",
    "# the training set.\n",
    "mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "X_dev = X_train[mask]\n",
    "y_dev = y_train[mask]\n",
    "\n",
    "# We use the first num_test points of the original test set as our\n",
    "# test set.\n",
    "mask = range(num_test)\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀5: Image-to-vector reshaping for all data\n",
    "\n",
    "모든 데이터를 32x32x3의 3차원 컬러 영상 형식에서 3072의 1차원 벡터 형식으로 변환함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Preprocessing: reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "\n",
    "# As a sanity check, print out the shapes of the data\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀6: Data preprocessing\n",
    "\n",
    "학습 데이터의 평균 벡터를 모든 dataset으로부터 빼 줌으로써 학습 데이터들의 평균을 원점으로 설정하고, 나머지 데이터들은 해당 학습 데이터의 원점을 기준으로 하도록 전처리를 수행함. 아울러 모든 데이터 벡터에 대해 bias parameter에 대응이 되는 차원을 하나 추가하고 해당 차원의 값을 1로 지정함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Preprocessing: subtract the mean image\n",
    "# first: compute the image mean based on the training data\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "print(mean_image[:10]) # print a few of the elements\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(mean_image.reshape((32,32,3)).astype('uint8')) # visualize the mean image\n",
    "plt.show()\n",
    "\n",
    "# second: subtract the mean image from train and test data\n",
    "X_train -= mean_image\n",
    "X_val -= mean_image\n",
    "X_test -= mean_image\n",
    "X_dev -= mean_image\n",
    "\n",
    "# third: append the bias dimension of ones (i.e. bias trick) so that our SVM\n",
    "# only has to worry about optimizing a single weight matrix W.\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 셀7-10: SVM Classifier\n",
    "\n",
    "다음 셀들은 Multiclass SVM loss function을 기반으로 하는 linear classification과 관련되며, 여러분이 직접 코드를 구현하여야 함. 이때 모든 코드는 `cs231n/classifiers/linear_svm.py` 파일 내에 구현함. \n",
    "\n",
    "### 셀7: SVM loss naive function 호출하여 SVM loss 값 계산\n",
    "\n",
    "다음 셀에서 확인되듯이, 제공되는 문제 파일들에 이미 loop를 기반으로 multiclass SVM loss function을 계산하는 함수 `svm_loss_naive`는 사전에 구현된 상태로 제공되며, 다음 셀들의 요구 사항을 직접 코드로 구현할 때 참고하도록 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the naive implementation of the loss we provided for you:\n",
    "from cs231n.classifiers.linear_svm import svm_loss_naive\n",
    "import time\n",
    "\n",
    "# generate a random SVM weight matrix of small numbers\n",
    "W = np.random.randn(3073, 10) * 0.0001 \n",
    "\n",
    "loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "print('loss: %f' % (loss, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀8: SVM loss naive 함수의 gradient 계산 코드 구현\n",
    "\n",
    "**구현 문제 1**:\n",
    "위 `svm_loss_naive` 함수에서 반환되는 변수 중 `grad` 값은 모두 0으로 반환됨. 함수 내에 해당 부분에 대한 코드는 구현되지 않고 비어있기 때문임. 따라서 강의동영상에 제시된 **Multiclass SVM loss 함수의 gradient 벡터를 직접 계산하여 도출하고, 이를 코드로 구현**하여 `svm_loss_naive` 함수를 완성하시오. \n",
    "이때, `cs231n/classifiers/linear_svm.py` 파일의 `svm_loss_naive` 함수 코드 내의 주석으로도 제시되어 있는 바와 같이, loss 값을 계산하는 이미 구현된 코드에 gradient를 계산하는 코드를 중간중간 삽입하는 방식으로 구현하면 더 편하게 구현할 수 있을 것이니 참고하시오.\n",
    "\n",
    "구현된 코드가 gradient 벡터 값을 제대로 계산했는지, 유효성을 검증하기 위해, 강의동영상에서 설명한 바와 같이 gradient를 수치적numerically으로도 근사하여 계산할 수 있음. 이를 수행하는 코드는 제공되는 코드의 `cs231n/gradient_check` 파일에 포함되어 있으며, 아래 셀에서는 이를 활용하도록 구현이 되어 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you've implemented the gradient, recompute it with the code below\n",
    "# and gradient check it with the function we provided for you\n",
    "\n",
    "# Compute the loss and its gradient at W.\n",
    "loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# Numerically compute the gradient along several randomly chosen dimensions, and\n",
    "# compare them with your analytically computed gradient. The numbers should match\n",
    "# almost exactly along all dimensions.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: svm_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad)\n",
    "\n",
    "# do the gradient check once again with regularization turned on\n",
    "# you didn't forget the regularization gradient did you?\n",
    "loss, grad = svm_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: svm_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "### **서술 문제 1**\n",
    "\n",
    "Analytic gradient을 잘 계산하고 구현하였다고 하더라도, Multiclass SVM loss 함수는 간혹 가다가 gradcheck로 도출된 gradient와 값이 달라지는 경우가 있을 수 있음. 단일 입력 변수 함수, 즉 1차원 예시에서 이렇게 gradcheck가 실패할 수 있는 경우를 생각해 보고, 어떤 경우에 이런 현상이 발생하는지 서술하시오. 아울러 이런 상황이 우려해야 하는, 즉 classfication 결과 또는 학습에 영향을 주는 상황인지, 아니면 결과적으로는 문제가 되지 않는 상황인지 근거를 들어 설명해 보시오. *Hint: SVM loss function는 엄밀히 미분가능하지 않음*\n",
    "\n",
    "$\\color{blue}{여러분의}$ $\\color{blue}{답:}$ *여기에 답을 작성하시오.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀9: SVM loss vectorized 중 loss 항 계산 코드 구현\n",
    "\n",
    "**구현 문제 2**: 아래 셀에서 호출되는 함수 `svm_loss_vectorized`의 내부 중 loss 값을 계산하는 부분을 구현하시오. (gradient 계산 부분은 아직 신경 쓰지 않아도 됨) \n",
    "이때 Data 변수들이 Numpy의 패키지의 ndarray이기 때문에, Numpy 패키지에 내장된 vectorization 방식의 고속 연산 기능을 활용할 수 있음. 참고로 vectorization 기능을 적절하게 활용할 경우 `svm_loss_naive`에 있었던 이중-for문 loop는 필요가 없어지며, 계산 결과는 `svm_loss_naive`와 동일하게 도출되지만 수행속도는 월등하게 빨라짐.\n",
    "\n",
    "**참고**: Numpy의 vectorization 기능에 익숙하지 않은 학생은 __[Numpy Tutorial](https://drive.google.com/file/d/19r82cvxCUYKXoDknE0Ig7hV5sGHkLrcR/view?usp=sharing)__을 참고하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vectorized_time_1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Next implement the function svm_loss_vectorized; for now only compute the loss;\n",
    "# we will implement the gradient in a moment.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = svm_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('Naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.linear_svm import svm_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, _ = svm_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('Vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# The losses should match but your vectorized implementation should be much faster.\n",
    "print('difference: %f' % (loss_naive - loss_vectorized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀10: SVM loss vectorized 중 gradient 항 계산 코드 구현\n",
    "\n",
    "**구현 문제 3**: 이제 아래 셀에서 호출되는 함수 `svm_loss_vectorized`의 내부 중 gradient 벡터를 계산하는 부분을 구현하시오. \n",
    "역시 vectorization 기능을 적절하게 활용할 경우 `svm_loss_naive`에 있었던 이중-for문 loop는 필요가 없어지며, 계산 결과는 `svm_loss_naive`와 동일하게 도출되지만 수행속도는 월등하게 빨라짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vectorized_time_2"
   },
   "outputs": [],
   "source": [
    "# Complete the implementation of svm_loss_vectorized, and compute the gradient\n",
    "# of the loss function in a vectorized way.\n",
    "\n",
    "# The naive implementation and the vectorized implementation should match, but\n",
    "# the vectorized version should still be much faster.\n",
    "tic = time.time()\n",
    "_, grad_naive = svm_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('Naive loss and gradient: computed in %fs' % (toc - tic))\n",
    "\n",
    "tic = time.time()\n",
    "_, grad_vectorized = svm_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('Vectorized loss and gradient: computed in %fs' % (toc - tic))\n",
    "\n",
    "# The loss is a single number, so it is easy to compare the values computed\n",
    "# by the two implementations. The gradient on the other hand is a matrix, so\n",
    "# we use the Frobenius norm to compare them.\n",
    "difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('difference: %f' % difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 셀11-17: Stochastic Gradient Descent\n",
    "\n",
    "이제 loss, gradient 계산을 위한 효율적인 vectorized 코드를 구현하였으며, 계산된 gradient 결과는 checkgrad 테스트도 만족함. 이제는 SGD 알고리즘을 이용하여 loss를 최소화하는 linear classifier의 weight parameter를 도출하고자 함. \n",
    "이 부분에 대한 여러분의 코드는 `cs231n/classifiers/linear_classifier.py` 파일 내에 구현하면 됨.\n",
    "\n",
    "### 셀 11: SGD 알고리즘 구현\n",
    "\n",
    "**구현 문제 4**: 파일 `cs231n/classifiers/linear_classifier.py` 내 LinearClassifier class의 멤버 함수인 LinearClassifier.train() 함수의 구현을 완성하시오. 구현할 부분은 i) 데이터의 랜덤 샘플링을 통해 mini-batch를 생성하는 부분과 ii) 반환된 gradient 벡터를 이용하여 weight parameter 값을 업데이트 하는 두 부분으로 구성됨. \n",
    "참고로 해당 파일의 해당 함수 내에 주석에도 대략적인 설명이 되어 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgd"
   },
   "outputs": [],
   "source": [
    "# In the file linear_classifier.py, implement SGD in the function\n",
    "# LinearClassifier.train() and then run it with the code below.\n",
    "from cs231n.classifiers import LinearSVM\n",
    "svm = LinearSVM()\n",
    "tic = time.time()\n",
    "loss_hist = svm.train(X_train, y_train, learning_rate=1e-7, reg=2.5e4,\n",
    "                      num_iters=1500, verbose=True)\n",
    "toc = time.time()\n",
    "print('That took %fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀 12: 학습 과정의 loss 값 시각화\n",
    "\n",
    "아래의 셀은 위의 multiclass SVM loss를 기반으로 하는 linear classifier를 학습하는 과정에서의 loss 값들을 그래프로 표시한 것으로, loss 값이 적절하게 감소하였는지를 확인하게 해 주어 이를 토대로 SGD 알고리즘이 제대로 구현되었는지를 체크할 수 있게 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A useful debugging strategy is to plot the loss as a function of\n",
    "# iteration number:\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀 13: 학습된 linear classifier를 이용한 분류값 predict 함수 구현\n",
    "\n",
    "**구현 문제 5**: 파일 cs231n/classifiers/linear_classifier.py 내 LinearClassifier class의 멤버 함수인 LinearClassifier.predict() 함수의 구현을 완성하시오. 구현할 부분은 학습 후 저장된 weight parameter들을 이용하여 linear classifier의 출력값을 계산하는 부분임. 해당 파일의 해당 함수 내의 주석으로 결과 값을 저장할 변수를 안내함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate"
   },
   "outputs": [],
   "source": [
    "# Write the LinearClassifier.predict function and evaluate the performance on both the\n",
    "# training and validation set\n",
    "y_train_pred = svm.predict(X_train)\n",
    "print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))\n",
    "y_val_pred = svm.predict(X_val)\n",
    "print('validation accuracy: %f' % (np.mean(y_val == y_val_pred), ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀 14: Hyperparameter tuning\n",
    "\n",
    "**구현 문제 6**: 앞서 분할해 놓은 validation dataset을 이용하여 아래 셀에 learning rate 및 regularization 가중치 등 hyperparameter를 최적화하는 코드를 구현하시오. 상세한 내용은 아래 코드의 주석을 확인하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuning",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of about 0.39 on the validation set.\n",
    "\n",
    "# Note: you may see runtime/overflow warnings during hyper-parameter search. \n",
    "# This may be caused by extreme values, and is not a bug.\n",
    "\n",
    "# results is dictionary mapping tuples of the form\n",
    "# (learning_rate, regularization_strength) to tuples of the form\n",
    "# (training_accuracy, validation_accuracy). The accuracy is simply the fraction\n",
    "# of data points that are correctly classified.\n",
    "results = {}\n",
    "best_val = -1   # The highest validation accuracy that we have seen so far.\n",
    "best_svm = None # The LinearSVM object that achieved the highest validation rate.\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Write code that chooses the best hyperparameters by tuning on the validation #\n",
    "# set. For each combination of hyperparameters, train a linear SVM on the      #\n",
    "# training set, compute its accuracy on the training and validation sets, and  #\n",
    "# store these numbers in the results dictionary. In addition, store the best   #\n",
    "# validation accuracy in best_val and the LinearSVM object that achieves this  #\n",
    "# accuracy in best_svm.                                                        #\n",
    "#                                                                              #\n",
    "# Hint: You should use a small value for num_iters as you develop your         #\n",
    "# validation code so that the SVMs don't take much time to train; once you are #\n",
    "# confident that your validation code works, you should rerun the validation   #\n",
    "# code with a larger value for num_iters.                                      #\n",
    "################################################################################\n",
    "\n",
    "# Provided as a reference. You may or may not want to change these hyperparameters\n",
    "learning_rates = [1e-7, 5e-5]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "pass\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀 15: training set 및 validation set에 대한 hyperparameter 추세 시각화\n",
    "\n",
    "아래 셀에서는 위 셀에서 수행한 hyperparameter tuning 과정에서 계산된 각 hyperparameter의 값 별로 training 및 validation dataset에 대해 도출되는 정확도를 그래프로 시각화하여 줌. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize the cross-validation results\n",
    "import math\n",
    "import pdb\n",
    "\n",
    "# pdb.set_trace()\n",
    "\n",
    "x_scatter = [math.log10(x[0]) for x in results]\n",
    "y_scatter = [math.log10(x[1]) for x in results]\n",
    "\n",
    "# plot training accuracy\n",
    "marker_size = 100\n",
    "colors = [results[x][0] for x in results]\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.tight_layout(pad=3)\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)\n",
    "plt.colorbar()\n",
    "plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('CIFAR-10 training accuracy')\n",
    "\n",
    "# plot validation accuracy\n",
    "colors = [results[x][1] for x in results] # default size of markers is 20\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)\n",
    "plt.colorbar()\n",
    "plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('CIFAR-10 validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀 16: test set에 대한 성능 확인\n",
    "\n",
    "학습된 multiclass svm loss 기반의 linear classifier의 정확도를 test dataset에 대해서 측정하여 제시함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test"
   },
   "outputs": [],
   "source": [
    "# Evaluate the best svm on test set\n",
    "y_test_pred = best_svm.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('linear SVM on raw pixels final test set accuracy: %f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀 17: 학습된 class 별 weight parameter 시각화\n",
    "\n",
    "아래 셀에서는 강의03 강의동영상(슬라이드 36번)에서 설명되었던 linear classifier의 시각적 이해 관점에서, 학습된 multiclass svm loss 기반의 linear classifier의 class별 weight vector를 이미지로 시각화하여 제시함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize the learned weights for each class.\n",
    "# Depending on your choice of learning rate and regularization strength, these may\n",
    "# or may not be nice to look at.\n",
    "w = best_svm.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "      \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "### **서술 문제 2**\n",
    "\n",
    "시각화된 linear classifier들의 weight vector들이 무엇으로 보이는지, 왜 그렇게 보이는지 간단하게 제시하시오.\n",
    "\n",
    "$\\color{blue}{여러분의}$ $\\color{blue}{답:}$ *여기에 답을 작성하시오.*  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
